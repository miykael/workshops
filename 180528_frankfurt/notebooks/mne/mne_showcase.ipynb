{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNE (MEG + EEG analysis & visualization)\n",
    "\n",
    "[Main Homepage](https://mne-tools.github.io/stable/index.html)\n",
    "\n",
    "**Note:** Do not forget to install scipy version 0.19 (until scipy version 2.0.1 is released)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supporte data formats\n",
    "\n",
    "Datatype            | File format              | Extension | MNE-Python function\n",
    "--------------------|--------------------------|-----------|------------------------\n",
    "MEG                 | Elekta Neuromag          | .fif      | `mne.io.read_raw_fif()`\n",
    "MEG                 | 4-D Neuroimaging / BTI   | dir       | `mne.io.read_raw_bti()`\n",
    "MEG                 | CTF                      | dir       | `mne.io.read_raw_ctf()`\n",
    "MEG                 | KIT                      | sqd       | `mne.io.read_raw_kit()` and `mne.read_epochs_kit()`\n",
    "EEG                 | Brainvision              | .vhdr     | `mne.io.read_raw_brainvision()`\n",
    "EEG                 | Neuroscan CNT            | .cnt      | `mne.io.read_raw_cnt()`\n",
    "EEG                 | European data format     | .edf      | `mne.io.read_raw_edf()`\n",
    "EEG                 | Biosemi data format      | .bdf      | `mne.io.read_raw_edf()`\n",
    "EEG                 | General data format      | .gdf      | `mne.io.read_raw_edf()`\n",
    "EEG                 | EGI simple binary        | .egi      | `mne.io.read_raw_egi()`\n",
    "EEG                 | EGI MFF format           | .mff      | `mne.io.read_raw_egi()`\n",
    "EEG                 | EEGLAB                   | .set      | `mne.io.read_raw_eeglab()` and `mne.read_epochs_eeglab()`\n",
    "Electrode locations | elc, txt, csd, sfp, htps | Misc      | `mne.channels.read_montage()`\n",
    "Electrode locations | EEGLAB loc, locs, eloc   | Misc      | `mne.channels.read_montage()`\n",
    "\n",
    "For more see [here](https://mne-tools.github.io/stable/manual/io.html#importing-meg-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify file to use\n",
    "\n",
    "This is just an example file, downsampled to 100Hz, so don't get all crazy and critical on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'oddball_example-raw.fif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in raw data / raw objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_fif(fname, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "raw.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['bads']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference to average\n",
    "\n",
    "Now, let's set the reference to the average. (*Bad EEG channels are automatically excluded if they are properly set in ``info['bads']``.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.set_eeg_reference('average', projection=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to filter the data between 1Hz and 20 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.filter(1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "raw.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['bads']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove EOG artefacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many EOG artefacts. We will use ICA to correct these. For this, we create an ICA object\n",
    "and use its `.fit` method on a filtered copy of the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = 20\n",
    "ica = mne.preprocessing.ICA(n_components=n_components, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.fit(raw.copy().filter(8, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ica.plot_components(outlines=\"skirt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_properties(raw, picks=[8]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Artifact Correction\n",
    "\n",
    "For more investigations and cool automatic ICA classification, see: https://www.martinos.org/mne/dev/auto_tutorials/plot_artifacts_correction_ica.html#advanced-artifact-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mne.preprocessing import create_eog_epochs\n",
    "\n",
    "picks_eeg = mne.pick_types(raw.info, meg=False, eeg=True, eog=False,\n",
    "                           stim=False, exclude='bads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get single EOG trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eog_average = create_eog_epochs(raw, ch_name='FP1', picks=picks_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eog_average = eog_average.average()\n",
    "eog_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ica.plot_sources(eog_average, exclude=[6, 13]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eog_average.plot_joint(times=np.linspace(-0.5, 0.5, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eog_average.plot_image();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eog_average.plot_topo();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eog_average.plot_topomap(times=np.linspace(-0.5, 0.5, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts = ica.detect_artifacts(raw.copy(), eog_ch='FP1', eog_criterion=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts.exclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclude bad components\n",
    "\n",
    "We store \"bad\" components in the ica object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ica.exclude = artifacts.exclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare raw and corrected data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_out = ica.apply(raw.copy(), exclude=ica.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.apply(ica_out).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For epoching the data, we need event markers. Usually, these are stored in the `raw` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.find_events(ica_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`events` is simply an array (time in samples, zero, trigger);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_events(events[:100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For creating an `mne.Epochs` object, we require, in addition to the `raw` object and the `events` array, a dictionary of the intended condition names and the corresponding trigger numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_ids = {\"standard/stimulus\": 200, \"target/stimulus\": 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs_pre = mne.Epochs(ica_out.copy(), events, event_id=event_ids, preload=True, reject=dict(eeg=80e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.2f%% of epochs were dropped' % epochs_pre.drop_log_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_channels = np.sort([x for x in flatten([d for d in epochs_pre.drop_log if d != []])])\n",
    "bad_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_appearance = [(c, np.sum(bad_channels==c)) for c in np.unique(bad_channels)]\n",
    "channel_appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kick_out_threshold = 8\n",
    "exclude_channels = [c[0] for c in channel_appearance if c[1]>=kick_out_threshold]\n",
    "exclude_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ica_out.info['bads'] = exclude_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_out.interpolate_bads(reset_bads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(ica_out, events, event_id=event_ids, preload=True, reject=dict(eeg=80e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.2f%% of epochs were dropped' % epochs.drop_log_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot average curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.average().plot(titles=dict(eeg='Average reference'), show=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mne.Epochs` constructor has a number of options, such as time window lengths and rejection thresholds.\n",
    "Investigate them on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Correction\n",
    "`Epochs` objects also have various methods, different from `raw` objects - e.g., for baselining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = epochs.apply_baseline((None, 0))\n",
    "epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access only specific conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subselect only a sample of epochs, a dict-like access mode is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how tags selected by forward slashes - \"/\" - work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs[\"stimulus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot specific electrode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs[\"target\"].plot_image(picks=[13]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot GFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs[\"target\"].plot_image(combine='gfp', cmap=\"YlGnBu_r\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event related potentials (ERP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if we average an epoched dataset over trials, we can use the `mne.Evoked` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = epochs[\"target\"].average()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standard = epochs[\"standard\"].average()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly investigate evoked activity, the `Evoked` object has a number of plotting functions available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target.plot_joint(times='peaks', ts_args=dict(gfp=True));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard.plot_joint(times='peaks', ts_args=dict(gfp=True));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differences between two conditions\n",
    "\n",
    "For condition contrasts, you can use `mne.combine.evoked`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "difference = mne.combine_evoked((target, standard), weights=(.5, -.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference.plot_joint(times=.35, ts_args=dict(gfp=True));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference.plot_topomap(times='peaks');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To contrast multiple conditions, `mne.viz.plot_compare_evokeds` is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_compare_evokeds({\"target\": target, \"standard\": standard},\n",
    "                             truncate_yaxis=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation F-test on sensor data with 1D cluster level\n",
    "According to: https://martinos.org/mne/stable/auto_examples/stats/plot_cluster_stats_evoked.html#sphx-glr-auto-examples-stats-plot-cluster-stats-evoked-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mne.stats import permutation_cluster_test\n",
    "\n",
    "fdr_epoch = epochs.copy()\n",
    "fdr_epoch.drop_channels(['STI 014'])\n",
    "\n",
    "epochs1 = fdr_epoch['target']\n",
    "epochs2 = fdr_epoch['stimulus']\n",
    "\n",
    "condition1 = epochs1.get_data().std(1)  # GFP as 3D matrix\n",
    "condition2 = epochs2.get_data().std(1)  # GFP as 3D matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 4\n",
    "T_obs, clusters, cluster_p_values, H0 = permutation_cluster_test(\n",
    "    [condition1, condition2], n_permutations=10000, threshold=threshold, tail=1, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = epochs['target'].times\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(211)\n",
    "plt.title('GFP')\n",
    "plt.plot(times, condition1.mean(axis=0) - condition2.mean(axis=0),\n",
    "         label=\"GFP Contrast (Cond 1 - Cond 2)\")\n",
    "plt.ylabel(\"GFP\")\n",
    "plt.legend()\n",
    "plt.subplot(212)\n",
    "for i_c, c in enumerate(clusters):\n",
    "    c = c[0]\n",
    "    if cluster_p_values[i_c] <= 0.05:\n",
    "        h = plt.axvspan(times[c.start], times[c.stop - 1],\n",
    "                        color='r', alpha=0.3)\n",
    "    else:\n",
    "        plt.axvspan(times[c.start], times[c.stop - 1], color=(0.3, 0.3, 0.3),\n",
    "                    alpha=0.3)\n",
    "hf = plt.plot(times, T_obs, 'g')\n",
    "plt.legend(['cluster p-value < 0.05'])\n",
    "plt.xlabel(\"time (ms)\")\n",
    "plt.ylabel(\"f-values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVPA/decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we predict trial type from EEG activity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up and simplify things, we balance the epochs counts for the two trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.equalize_event_counts(event_ids);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.pick_types(eeg=True)\n",
    "X = epochs.get_data()  # features\n",
    "y = epochs.events[:, -1] == event_ids[\"target/stimulus\"]  # targets\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X has the wrong shape - `samples`, `channels`, `times`, should be `samples`, `features`.\n",
    "\n",
    "We can use `mne.decoding.Vectorizer` to correctly shape the data. It fits right into a scikit-learn pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mne.decoding import Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(Vectorizer(), StandardScaler(), LinearSVC(class_weight=\"balanced\"))\n",
    "res = cross_val_score(clf, X, y, cv=8)  # accuracy\n",
    "print(np.round(res.mean() * 100, 3))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression(class_weight=\"balanced\"))\n",
    "res = cross_val_score(clf, X, y, cv=8)  # accuracy\n",
    "print(np.round(res.mean() * 100, 3))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = make_pipeline(Vectorizer(), StandardScaler(), RandomForestClassifier(class_weight=\"balanced\"))\n",
    "res = cross_val_score(clf, X, y, cv=8)  # accuracy\n",
    "print(np.round(res.mean() * 100, 3))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kind of Searchlight - Classification over time\n",
    "\n",
    "At which time points in the trial is there information about trial category?\n",
    "\n",
    "We need two more tools for this: one to train and score at each time point, and one to handle the cross-validated scoring for the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mne.decoding import SlidingEstimator, cross_val_multiscore, LinearModel, get_coef\n",
    "clf = make_pipeline(Vectorizer(), StandardScaler(), LinearModel(LinearSVC(class_weight=\"balanced\")))\n",
    "sl = SlidingEstimator(clf, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_time_decoding = cross_val_multiscore(sl, X, y, cv=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(epochs.times, scores_time_decoding.mean(0), label='score')\n",
    "ax.axhline(.5, color='k', linestyle='-', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='--')\n",
    "ax.set_title('Sensor space decoding')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can retrieve the spatial filters and spatial patterns if you explicitly use a LinearModel\n",
    "sl.fit(X, y)\n",
    "coef = get_coef(sl, 'patterns_', inverse_transform=True)\n",
    "evoked = mne.EvokedArray(coef, epochs.info, tmin=epochs.times[0])\n",
    "evoked.plot_joint(times='peaks', title='patterns');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But is the same thing happening at each time point? We can investigate that with generalization across time decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mne.decoding import GeneralizingEstimator\n",
    "gen = GeneralizingEstimator(clf)\n",
    "scores_gat = cross_val_multiscore(gen, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_gat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = scores_gat.mean(0)\n",
    "vmax = np.abs(data).max()\n",
    "tmin, tmax = epochs.times[[0, -1]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "im = ax.imshow(\n",
    "    data,\n",
    "    origin=\"lower\", cmap=\"RdBu_r\",\n",
    "    extent=(tmin, tmax, tmin, tmax),\n",
    "    vmax=vmax, vmin=1-vmax);\n",
    "\n",
    "ax.set_xlabel('Testing Time (s)')\n",
    "ax.set_ylabel('Training Time (s)')\n",
    "ax.set_title('Temporal Generalization')\n",
    "ax.axvline(0, color='k')\n",
    "ax.axhline(0, color='k')\n",
    "\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horizontal line means. If we take a classifier at timepoint (x,y), how well does this predict the timepoint x ms later?\n",
    "\n",
    "So in this figure it means. Around the middle blob (around 180ms), something else happens that in the upper right corner (450ms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Frequency stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an overview over the spectral shape of the data, we can use a plotting method of `raw`, `raw.plot_psd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_psd(fmin=1, fmax=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very green high curve is actually the eye blinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.apply(raw.copy(), exclude=[0, 6]).plot_psd(fmin=1, fmax=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure above is not specific to time. It overall time points.\n",
    "\n",
    "But what about the time/frequency correlates of the Oddball effect?\n",
    "\n",
    "We will extract power per time and frequency with Morlet wavelets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mne.time_frequency import tfr_morlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_for_tfr = mne.Epochs(raw, events, event_id=event_ids,\n",
    "                            tmin=-.5, tmax=1.5, preload=True)  # need longer data segment\n",
    "epochs_for_tfr = ica.apply(epochs_for_tfr, exclude=ica.exclude)\n",
    "epochs_for_tfr.equalize_event_counts(event_ids);  # to speed up things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freqs = np.arange(3, 30)\n",
    "tfr_target = tfr_morlet(epochs_for_tfr[\"target\"], freqs, 3, return_itc=False)\n",
    "tfr_standard = tfr_morlet(epochs_for_tfr[\"standard\"], freqs, 3, return_itc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-frequency data (single trial or averaged) is stored in TFR objects. These objects behave in many ways like Evoked objects ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr = mne.combine_evoked((tfr_standard, tfr_target), (-.5, .5))\n",
    "tfr.apply_baseline((None, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting time-frequencyy activity (event-related spectral perturbations): observe the alpha-band ERD and the time-frequency correlates of the P3 effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr.plot(picks=[27]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we see is a contrast between the standards and targets. So it means, that in the targets, the alpha activity goes down at 400ms in contrast to standard stimuli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster-based permutation stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory analysis with nonparametric control of the error rate is commonly done with\n",
    "cluster-based permutation tests (i.e., Maris 2012). To cluster across space, we first need a\n",
    "channel adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.channels import find_ch_connectivity\n",
    "connectivity, ch_names = find_ch_connectivity(epochs.info, ch_type='eeg')\n",
    "plt.imshow(connectivity.toarray(), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see which channels are adjacent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need the data in the right shape. Sadly, because the space dimension needs\n",
    "to be last, we need to manually swap the time and space axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.pick_types(eeg=True)\n",
    "target_epochs, standard_epochs = epochs[\"target\"].get_data(), epochs[\"standard\"].get_data()\n",
    "target_epochs.shape, standard_epochs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_epochs = target_epochs.swapaxes(1, 2)\n",
    "standard_epochs = standard_epochs.swapaxes(1, 2)\n",
    "target_epochs.shape, standard_epochs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNE has various cluster-based permutation test options. Here, we test for single-trial\n",
    "differences between conditions with `mne.stats.spatio_temporal_cluster_test`.\n",
    "\n",
    "We use threshold-free cluster enhancement to reduce the number of parameters.\n",
    "\n",
    "Warning: the next cell takes a lot of time and computational power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.stats import spatio_temporal_cluster_test\n",
    "\n",
    "tfce = dict(start=.1, step=.3)\n",
    "cluster_stats = spatio_temporal_cluster_test([target_epochs, standard_epochs],\n",
    "                                             threshold=tfce,\n",
    "                                             n_permutations=256,\n",
    "                                             n_jobs=-1,\n",
    "                                             connectivity=connectivity)\n",
    "T_obs, clusters, p_values, _ = cluster_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualise the *t* values over time and space ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = (*epochs.times[[0, -1]], 0, len(epochs.ch_names))\n",
    "im = plt.imshow(T_obs.T, aspect=\"auto\", cmap=\"RdBu_r\",\n",
    "                vmin=-100, vmax=100, extent=extent\n",
    "          )\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(p_values)\n",
    "\n",
    "alpha = .01\n",
    "print(sum(p_values < alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(p_values.reshape(T_obs.shape).T < alpha, aspect=\"auto\", cmap=\"Reds\",\n",
    "           extent=extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot((p_values.reshape(T_obs.shape).T < alpha).mean(0) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametric stats\n",
    "Sometimes, e.g. because we wish to test a specific hypothesis, cluster-based permutation tests are too much.\n",
    "We can also simply access the data in array form and test with parametric (or nonparametric) tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, we first need to identify the spatial and temporal coordinates of an effect we want to test -\n",
    "for example, the N2 at Cz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_mask = (.2 < epochs.times) & (epochs.times < .25)\n",
    "plt.plot(time_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract the target data. Reminder: the shape of epochs data is (trial, channel, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs[\"target\"].get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cond_a = epochs[\"target\"].get_data()[:, :, time_mask].std(1).mean(-1)\n",
    "cond_b = epochs[\"standard\"].get_data()[:, :, time_mask].std(1).mean(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply use ordinary tests on these statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(cond_a, cond_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilcoxon(cond_a, cond_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also straight-forward to convert the data into a (pandas) dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = epochs.to_data_frame()\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cz = df.query(\"200 < time < 250\")[\"Cz\"].groupby([\"epoch\", \"condition\"]).mean().reset_index()\n",
    "df_cz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.factorplot(y=\"Cz\", data=df_cz, x=\"condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary\n",
    "\n",
    "- [Sort your ERP by reaction time (RT)](https://mne-tools.github.io/stable/auto_examples/visualization/plot_roi_erpimage_by_rt.html#sphx-glr-auto-examples-visualization-plot-roi-erpimage-by-rt-py)\n",
    "- [FDR correction on T-test on sensor data](https://mne-tools.github.io/stable/auto_examples/stats/plot_fdr_stats_evoked.html)\n",
    "- [Permutation t-test on source data with spatio-temporal clustering](https://mne-tools.github.io/stable/auto_tutorials/plot_stats_cluster_spatio_temporal.html)\n",
    "- [Compute effect-matched-spatial filtering (EMS)](https://martinos.org/mne/stable/auto_examples/decoding/plot_ems_filtering.html#sphx-glr-auto-examples-decoding-plot-ems-filtering-py)\n",
    "- [Plotting the full MNE solution](https://mne-tools.github.io/stable/auto_examples/inverse/plot_vector_mne_solution.html#sphx-glr-auto-examples-inverse-plot-vector-mne-solution-py)\n",
    "- [XDAWN Denoising](https://mne-tools.github.io/stable/auto_examples/preprocessing/plot_xdawn_denoising.html)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mne]",
   "language": "python",
   "name": "conda-env-mne-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
